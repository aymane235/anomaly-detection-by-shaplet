{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79944ef0",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Before running this notebook, ensure the following:\n",
    "\n",
    "- The files `classes.ipynb` and `utilities.py` are located in the same directory as this notebook.\n",
    "- The following libraries are installed in your Python environment:\n",
    "\n",
    "  - `importlib`\n",
    "  - `bisect`\n",
    "  - `sys`\n",
    "  - `pickle`\n",
    "  - `time`\n",
    "  - `numpy`\n",
    "  - `seaborn`\n",
    "  - `matplotlib.pyplot`\n",
    "  - `mplcursors`\n",
    "  - `pandas`\n",
    "  - `scipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utilities\n",
    "%run classes.ipynb       \n",
    "import bisect\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import linregress \n",
    "from scipy.fft import fft, rfft,fftshift\n",
    "from scipy.fft import fftfreq, rfftfreq\n",
    "import scipy.signal as sig\n",
    "from scipy.fft import fft, rfft,fftshift\n",
    "from scipy.fft import fftfreq, rfftfreq\n",
    "import sys\n",
    "import pickle\n",
    "import bisect\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe54731-a472-4df5-9c78-8858b714d522",
   "metadata": {},
   "source": [
    "# Please indicate here the path to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a3e70-28f0-4782-a539-961b6dd4ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_path( \"/Users/gangler/data/GRS1915+105/classified_lcs\") #<my_path> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce4248",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used in this notebook can be downloaded from the following link:  \n",
    "[GRS 1915+105 Hand-Annotated RXTE Light Curves](https://figshare.com/articles/dataset/GRS_1915_105_Hand-Annotated_RXTE_Light_Curves/4220409?file=6886539)\n",
    "\n",
    "For more details about the dataset, please refer to the `README.md` file.\n",
    "\n",
    "> **Note:** Information about the dataset will be added to the README or documented in a dedicated notebook.  \n",
    "### TODO: Add dataset documentation in the README or a separate notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### Precomputed Mappings\n",
    "\n",
    "The JSON files corresponding to the dictionaries `class2key` and `key2class` are already included in this repository.\n",
    "\n",
    "- `class2key.json`: maps each class label to a list of light curve indices belonging to that class.\n",
    "- `key2class.json`: maps each light curve index to its corresponding class label.\n",
    "\n",
    "These files were generated from the dataset annotations and are provided here for convenience. You can load them directly to avoid rebuilding these mappings from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "key2class=utilities.loadjson(\"key2class\")\n",
    "class2key=utilities.loadjson(\"class2key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e17bce",
   "metadata": {},
   "source": [
    "### Visualization Setup\n",
    "\n",
    "Now, we initialize an object from the `Visualizer` class. This class contains all the plotting functions and is completely **independent** from the data computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer=Visualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c5d52",
   "metadata": {},
   "source": [
    "### Data Loading and Normalization\n",
    "\n",
    "The following code performs two main tasks:\n",
    "\n",
    "1. **Load and store data efficiently:**  \n",
    "   To avoid loading data multiple times, we create a dictionary `data` that stores the `Data` objects for all light curve indices in the `\"rho\"` class.\n",
    "\n",
    "2. **Normalize the data:**  \n",
    "   For each light curve in the `\"rho\"` class, we calculate a normalization factor called `alpha` using a utility function. Then, we create a dictionary `normalizeddata` that stores the normalized data corresponding to each light curve index.\n",
    "\n",
    "This approach ensures that data loading and normalization are done once, improving efficiency when working with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ebb673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data in one dictionary to not load each time\n",
    "data={}\n",
    "for i in class2key[\"rho\"]:\n",
    "    data[i]=Data(i)\n",
    "#saving normalized data and the factor of normalization that i called alpha\n",
    "alpha={}\n",
    "normalizeddata={}\n",
    "for i in class2key[\"rho\"]:\n",
    "    alpha[i]=utilities.findalpha(data[i].getcolumn(\"low\"))\n",
    "    normalizeddata[i]=normalizedData(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc440b28",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b945388",
   "metadata": {},
   "source": [
    "### before starting please make sure that the file name;data storage file, in the class notebook is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc181=data[181]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d09732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get low column:\n",
    "lc181low=lc181.low()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw the low column of lc 181\n",
    "utilities.show(lc181low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e8471",
   "metadata": {},
   "source": [
    "## Shaplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "#lcnumber,column,start,length,alpha=-1,mean=-1,isaclean=False,series=None,isnormalized=False\n",
    "\n",
    "#alpha is the coefficient used for z normalization, 1 / (standard deviation)\n",
    "#mean is the mean of the shaplet\n",
    "\n",
    "#alpha are mean are saved in the shaplet in case its normalized and one needs to retrieve the previous paramters\n",
    "\n",
    "#is a clean means is set to be True if the shaplet is averaged or not\n",
    "#isnomralized is set to be True if the shaplet is normalized\n",
    "\n",
    "#for this tutorial i ll leave everything that can be defaulted to the default value\n",
    "sh=Shaplet(181,\"low\",0,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed6106",
   "metadata": {},
   "source": [
    "## Comparator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75260c",
   "metadata": {},
   "source": [
    "if there is any important class in the class notebook,its gonna be this one\n",
    "this is where all the computations are done,mainly TO COMPARE the shaplet and the comparator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comp takes for input (Data,column,shaplet) Data object,the column of data on which the comparison will be done,and a shaplet object\n",
    "comp=Comparator(lc181,\"low\",sh)\n",
    "\n",
    "#Main comparator functionalities: \n",
    "\n",
    "#get the chi2 difference: \n",
    "chi2=comp.chi2()\n",
    "\n",
    "#getting the minimas:\n",
    "minimas=comp.minimas()\n",
    "\n",
    "#finding the minimas positions: \n",
    "minimaspositions=comp.minimaspositions()\n",
    "\n",
    "#NOTE: THE MOST COSTLY OPERATION IS THE CHI2 MEASUREMENT,AND ONCE ITS DONE,ITS SAVED IN THE CLASS\n",
    "#      ONE CAN DIRECTLY CALL MINIMASPOSITIONS OR MINIMAS,THE FUNCTIONS WILL CALL CHI2 MEASUREMENT BY THEMSELFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e3172",
   "metadata": {},
   "source": [
    "## Visualizer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a96084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once the chi2 is computed,we superpose the shaplet on the lightcurve at the ressanblance points\n",
    "#for this task,we use the superpose function in visualizer,we pass the comparator to it\n",
    "visualizer.superpose(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc0e48",
   "metadata": {},
   "source": [
    "## Dictionary building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the code for dictionary building shaplet definition and lc curves encoding analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dacabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of the shaplet to be defined and set,its one of the free parameters,\n",
    "#for more about the free parameters,check free paramters table below\n",
    "shapletlength=300\n",
    "\n",
    "#shaplet list that i ll fill up: \n",
    "shaplets:list[Shaplet]=[]\n",
    "\n",
    "#a shaplet 0 initialized,one can choose any shaplet,the paramters lcnumber and start can be choosen randomly\n",
    "#In fact,the algorithm should work regardless of the initial shaplet\n",
    "lcnumber=432\n",
    "start=0\n",
    "shaplet0=Shaplet(lcnumber,\"low\",start,shapletlength,isnormalized=True) #column,start,length,isaclean=False,series=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfd453",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.show(shaplet0.series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a86889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to track intervals where shaplets were actually taken\n",
    "# Algorithm can be optimized by saving only the two sup,inf points defining avoidance regions\n",
    "# and going through each interval rather in a simple algorithm to check if the point is in one of those\n",
    "\n",
    "\n",
    "avoidanceregion={}\n",
    "from scipy.signal import argrelmin\n",
    "from collections import defaultdict\n",
    "\n",
    "def builddictionarynew(shaplets: list, k: list,comparators: dict):\n",
    "    print(\"Size of the dictionary:\", len(shaplets))\n",
    "\n",
    "    if len(shaplets) > 50:\n",
    "        print(\"More than 50 shaplets reached.\")\n",
    "        return\n",
    "\n",
    "    global selected_intervals\n",
    "    key = -1\n",
    "    best_shaplet = None\n",
    "    best_chi2_list = None\n",
    "    best_interval = None\n",
    "\n",
    "    for i in class2key[\"rho\"]:\n",
    "        \n",
    "        if i not in comparators:\n",
    "            comparators[i] = []\n",
    "\n",
    "        if i not in avoidanceregion:\n",
    "            avoidanceregion[i] = set()\n",
    "            \n",
    "            \n",
    "        comparator = Comparator(normalizeddata[i], \"low\", shaplets[-1])\n",
    "        comparators[i].append(comparator)\n",
    "\n",
    "        \n",
    "        comparatorlist = comparators[i]\n",
    "        chi2list = [comparator.chi2() for comparator in comparatorlist]\n",
    "        chi2matrix = np.array(chi2list)\n",
    "\n",
    "        # building the NEW MINCHI2 = min(chi2_1,chi2_2,...)\n",
    "        minimumchi2 = chi2matrix[np.argmin(chi2matrix, axis=0), np.arange(chi2matrix.shape[1])]\n",
    "\n",
    "        # finding minimas on the NEWLY made minchi2\n",
    "        min_window = shapletlength // 3\n",
    "        minimaindeces = argrelmin(minimumchi2, order=min_window)[0]\n",
    "    #    minimaindeces = [i for i in minimaindeces if minimumchi2[i] < 3]   #THE CUT IS 3\n",
    "\n",
    "        # Add boundaries if needed\n",
    "  #      if len(minimaindeces) < 2:\n",
    "  #          continue\n",
    "     #   minima = np.insert(minima, 0, 0)\n",
    "    #    minima = np.append(minima, len(minimumchi2) - 1)\n",
    "\n",
    "        \n",
    "        #avoidance region length:\n",
    "        avoidancesize=len(shaplets[0])//3\n",
    "        \n",
    "        for minim in minimaindeces:\n",
    "            avoidanceregion[i] = avoidanceregion[i] | set( range(max(0,minim-avoidancesize) ,min(minim+avoidancesize,len(minimumchi2))) )\n",
    "       \n",
    "        valid_indices = [j for j in range(len(minimumchi2)) if j not in avoidanceregion[i]] # chnage and add minus sets\n",
    "        validminchi2 = [minimumchi2[j] for j in valid_indices]\n",
    "\n",
    "        \n",
    "        \n",
    "        chi2max=-1\n",
    "        if len(validminchi2)>0:\n",
    "            local_max_idx_valid = np.argmax(validminchi2) # need to get bac\n",
    "            chi2max = validminchi2[local_max_idx_valid]\n",
    "            local_max_idx = valid_indices[local_max_idx_valid]\n",
    "        \n",
    "        # minchi2[]\n",
    "        #  GET BACK TO THE MINCHI2 : minimaindeces = [i for i in minimaindeces if minimumchi2[i] < 3]\n",
    "\n",
    "        #\n",
    "        if chi2max < 3:\n",
    "            continue  # Skip low-significance results\n",
    "\n",
    "        if chi2max > key:\n",
    "            key = chi2max\n",
    "            best_chi2_list = chi2matrix\n",
    "            mean = getmean(i, local_max_idx, 300)\n",
    "            alpha = utilities.findalpha(data[i].getcolumn(\"low\"))\n",
    "            best_shaplet = Shaplet(i, \"low\", local_max_idx, shapletlength, mean=mean, alpha=alpha, isnormalized=True)\n",
    "\n",
    "    if best_shaplet:\n",
    "        print(\"Selected shaplet with chi2:\", key)\n",
    "        shaplets.append(best_shaplet)\n",
    "        chi2selected.append(best_chi2_list)\n",
    "        k.append(key)\n",
    "        builddictionary(shaplets, k,comparators)\n",
    "    else:\n",
    "        print(\"No suitable shaplet found in this pass.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b556f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
