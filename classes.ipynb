{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4b7519-dc8e-4dbe-a129-e8003860b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utilities\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import linregress \n",
    "from scipy.fft import fft, rfft,fftshift\n",
    "from scipy.fft import fftfreq, rfftfreq\n",
    "import scipy.signal as sig\n",
    "from scipy.fft import fft, rfft,fftshift\n",
    "from scipy.fft import fftfreq, rfftfreq\n",
    "import sys\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b986d72-d7d9-4982-9e91-fd5f463b55f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMARK: WHEN RELOADING THIS FILE IN THE OTHER NOTEBOOK,THE ISINSTANCE WONT RECOGNIZE THE CLASSES\n",
    "#BECAUSE THE VERSION DEFINED WAS THE VERSION FROM THE PREVIOUS VERSION OF THE NOTEBOOK !!!!!!!\n",
    "\n",
    "# free parameters:\n",
    "# order of windowing\n",
    "# chi2 to decide parts of lc to take for averaging\n",
    "\n",
    "#TODOS:\n",
    "#NEED MAXMINEFFICIENT TABLE FOR AVERAGE SHAPLET AND WITH NORMALIZED COMPARATOR FOR RHO AND ALL\n",
    "#TEST THE CHI2 < 2 FOR CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c4999-b7ca-4db2-9ee7-7a4fb2eba540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f440c2-1127-4ec4-ad33-9365008f2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the Data class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3995ab7c-f5fe-40a1-b6b9-9bf513d133f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utilities)\n",
    "\n",
    "class Data:\n",
    "    def __init__(self,lcnumber):\n",
    "        self.lcnumber=lcnumber\n",
    "        self.datatable=None\n",
    "        self.dataclass=None\n",
    "        self.__load()\n",
    "        self.cumsumLow=np.cumsum(self.getcolumn(\"low\"))\n",
    "        self.cumsumMid=np.cumsum(self.getcolumn(\"mid\"))\n",
    "        self.cumsumHigh=np.cumsum(self.getcolumn(\"high\"))\n",
    "        self._alpha={\"low\":None,\"mid\":None,\"high\":None}\n",
    "        self._beta={\"low\":None,\"mid\":None,\"high\":None}\n",
    "\n",
    "    def _findalpha(self,column):\n",
    "         self._alpha[column]=utilities.findalpha(self.getcolumn(column))\n",
    "\n",
    "    def _findbeta(self,column):\n",
    "        self._beta[column]=utilities.findbeta(self.getcolumn(column))\n",
    "    \n",
    "    def alpha(self,column):\n",
    "        if(self._alpha[column] is None):\n",
    "            self._findalpha(column)\n",
    "        return self._alpha[column]\n",
    "\n",
    "    def beta(self,column):\n",
    "        if(self._beta[column] is None):\n",
    "            self._findbeta(column)\n",
    "        return self._beta[column]\n",
    "    \n",
    "    def __load(self):\n",
    "        self.datatable=pd.read_csv(\"classified_lcs/grs1915_lc\"+str(self.lcnumber)+\".txt\",sep=\"\t\",skiprows=[0, 1], header=None)\n",
    "        self.datatable.columns=['time', 'total','low','mid','high'] \n",
    "        \n",
    "        firstline=pd.read_csv(\"classified_lcs/grs1915_lc\"+str(self.lcnumber)+\".txt\",sep=\"\t\",nrows=1, header=None).iloc[0,0]\n",
    "        prefix=\"# class : \"\n",
    "        self.dataclass=firstline[len(prefix):].strip()\n",
    "\n",
    "    \n",
    "    def low(self):\n",
    "        return np.array(self.datatable[\"low\"])\n",
    "\n",
    "    def mid(self):\n",
    "        return np.array(self.datatable[\"mid\"])\n",
    "\n",
    "    def high(self):\n",
    "        return np.array(self.datatable[\"high\"])\n",
    "\n",
    "    def getcolumn(self,column):\n",
    "        if(column==\"low\"):\n",
    "            return self.low()\n",
    "        if(column==\"mid\"):\n",
    "            return self.mid()\n",
    "        if(column==\"high\"):\n",
    "            return self.high()\n",
    "            \n",
    "    def cumsum(self,column):\n",
    "        if(column==\"low\"):\n",
    "            return self.cumsumLow\n",
    "        if(column==\"mid\"):\n",
    "            return self.cumsumMid\n",
    "        if(column==\"high\"):\n",
    "            return self.cumsumHigh\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01848ce8-3b18-408d-a2c1-32e03c80c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalizedData(Data):\n",
    "    def __init__(self,lcnumber):\n",
    "        self.lcnumber=lcnumber\n",
    "        self.datatable=None\n",
    "        self.dataclass=None\n",
    "        self.__normalizedload()\n",
    "        self.cumsumLow=np.cumsum(self.getcolumn(\"low\"))\n",
    "        self.cumsumMid=np.cumsum(self.getcolumn(\"mid\"))\n",
    "        self.cumsumHigh=np.cumsum(self.getcolumn(\"high\"))\n",
    "        self._alpha={\"low\":None,\"mid\":None,\"high\":None}\n",
    "        self._beta={\"low\":None,\"mid\":None,\"high\":None}\n",
    "        \n",
    "    def __normalizedload(self):\n",
    "        self.datatable=pd.read_csv(\"classified_lcs/grs1915_lc\"+str(self.lcnumber)+\".txt\",sep=\"\t\",skiprows=[0, 1], header=None)\n",
    "        self.datatable.columns=['time', 'total','low','mid','high'] \n",
    "        for c in self.datatable.columns:\n",
    "            self.datatable[c]=utilities.normalize(self.datatable[c])\n",
    "            \n",
    "        firstline=pd.read_csv(\"classified_lcs/grs1915_lc\"+str(self.lcnumber)+\".txt\",sep=\"\t\",nrows=1, header=None).iloc[0,0]\n",
    "        prefix=\"# class : \"\n",
    "        self.dataclass=firstline[len(prefix):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f2e9d7-41a4-4c52-963c-1372bf871e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Shaplet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b39fbf-e4d6-4a5c-8eca-aecea758179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utilities)\n",
    "class Shaplet:\n",
    "    def __init__(self,lcnumber,column,start,length,alpha=-1,mean=-1,isaclean=False,series=None,isnormalized=False):\n",
    "        self.isnormalized=isnormalized\n",
    "        self.isaclean=isaclean\n",
    "        if not (series is None):\n",
    "            self.series=series\n",
    "            self.lcnumber=lcnumber              #THIS SHOULD CHANGE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            self.column=column\n",
    "            self.start=start\n",
    "            self.length=len(self.series)\n",
    "        else:\n",
    "            self.lcnumber=lcnumber\n",
    "            self.start=start\n",
    "            self.column=column\n",
    "            self.length=length\n",
    "            self.end=start+length\n",
    "            self.series=None\n",
    "            if(isnormalized):\n",
    "                self.load(normalizedData(self.lcnumber))\n",
    "            else:\n",
    "               # print(\"get here too\")\n",
    "                self.load(Data(self.lcnumber))\n",
    "        self.sum=np.sum(self.series)\n",
    "        self.alpha=utilities.findalpha(self.series)\n",
    "        self.beta=utilities.findbeta(self.series)\n",
    "        self.mean=mean\n",
    "        self.alpha=alpha\n",
    "        \n",
    "        \n",
    "    def normalizeserie(self):\n",
    "        self.series=self.alpha*self.series+self.beta\n",
    "\n",
    "    def getnormalizedserie(self):\n",
    "        return self.alpha*self.series+self.beta\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    #i will leave it right now public,we will see what we can do in the future\n",
    "    def load(self,data):\n",
    "        if data.lcnumber != self.lcnumber:\n",
    "            raise ValueError(\"Error: lcnumber values do not match.\")  # Raising an error properly\n",
    "        if(self.series is None):\n",
    "            #print(data.getcolumn(self.column)[self.start:self.end])\n",
    "            self.series=data.getcolumn(self.column)[self.start:self.end]\n",
    "            #print(self.series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9e061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953dce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f35c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87498c0a-0494-4db4-84ab-a5a7256efeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utilities)\n",
    "class Comparator:\n",
    "    def __init__(self,data:Data,column,shaplet:Shaplet):\n",
    "        self.data=data\n",
    "        self.shaplet=shaplet\n",
    "        self.column=column\n",
    "        self.signallength=len(data.getcolumn(column))\n",
    "        \n",
    "        \n",
    "        self._chi2=None\n",
    "        self._minimaspositions=None\n",
    "        self._minimas=None\n",
    "        \n",
    "        self._maxCut=None\n",
    "        self._minCut=None\n",
    "        self._efficientCut=None\n",
    "        self.cumsum=self.data.cumsum(self.column)\n",
    "        self.alpha=np.ones( max(len(self.cumsum) - len(self.shaplet)+1,0) )\n",
    "        self._scaledchi2=None\n",
    "    \n",
    "    def __computealpha(self):\n",
    "        s=self.cumsum\n",
    "        signal=self.data.getcolumn(self.column)\n",
    "        N=len(self.shaplet)\n",
    "        alpha=np.array([s[N-1]])\n",
    "        alpha=np.concatenate((alpha,self.cumsum[N:]-self.cumsum[:-N]))\n",
    "        alpha=alpha/np.sum(self.shaplet.series) \n",
    "        return alpha\n",
    "\n",
    "    def scaledchi2measure(self,signal,shapletseries):\n",
    "        #NEED TO CHECK IF THE SHAPLET SERIES IS LOADED IF NOT THEN I LL HAE AN ERROR \n",
    "        if(len(signal)<len(shapletseries)): #By convention the difference is -1 if the sizes arent matching\n",
    "            return np.array(-1)\n",
    "            \n",
    "        difference=[] #diffrence between shaplet & signal\n",
    "        mean_=np.mean(shapletseries)\n",
    "        shapletlength=len(shapletseries)\n",
    "        for i in range(0,len(signal)-len(shapletseries)):\n",
    "            alpha=self.alpha[i]\n",
    "            diff=np.sum(np.power(signal[i:i+len(shapletseries)]-alpha*shapletseries,2) / ((alpha+alpha**2)*mean_*8*len(shapletseries)))\n",
    "            difference.append(diff)\n",
    "        difference=np.array(difference)\n",
    "        return difference\n",
    "        \n",
    "    @staticmethod\n",
    "    def chi2measure(signal,shaplet:Shaplet,alpha=None,mean=None):\n",
    "    #NEED TO CHECK IF THE SHAPLET SERIES IS LOADED IF NOT THEN I LL HAE AN ERROR !!!------------------------------------------------------------------------\n",
    "        if(len(signal)<len(shaplet)): #By convention the difference is -1 if the sizes arent matching\n",
    "            return np.array(-1)\n",
    "        difference=[] #diffrence between shaplet & signal\n",
    "        mean_=np.mean(shaplet.series)\n",
    "        shapletlength=len(shaplet)\n",
    "        for i in range(0,len(signal)-len(shaplet)):\n",
    "            if(not shaplet.isnormalized):\n",
    "                diff=np.sum(np.power(signal[i:i+len(shaplet)]-shaplet.series,2) / (2*mean_*8*len(shaplet)) )\n",
    "            else:\n",
    "                diff=np.sum(np.power(signal[i:i+len(shaplet)]-shaplet.series,2) / (2*(shaplet.mean)*(shaplet.alpha**2)*8*len(shaplet)) )\n",
    "            difference.append(diff)\n",
    "        difference=np.array(difference)\n",
    "        return difference\n",
    "\n",
    "    def __chi2measure(self):\n",
    "        if self._chi2 is None:\n",
    "            self._chi2=Comparator.chi2measure(self.data.getcolumn(self.column),self.shaplet)\n",
    "\n",
    "    def __scaledchi2measuring(self):\n",
    "        if self._scaledchi2 is None:\n",
    "            self._scaledchi2=self.scaledchi2measure(self.data.getcolumn(self.column),self.shaplet.series)\n",
    "    \n",
    "    def chi2(self):\n",
    "        self.__chi2measure()\n",
    "        return self._chi2\n",
    "\n",
    "    def scaledchi2(self):\n",
    "        self.__scaledchi2measuring()\n",
    "        return self._scaledchi2\n",
    "    \n",
    "    def __findminimas(self):\n",
    "        self.__chi2measure()\n",
    "        \n",
    "        if np.array_equal(self._chi2,np.array(-1)):\n",
    "            self._minimas=np.array(-1)\n",
    "            self._minimaspositions=np.array(-1)\n",
    "            self._minCut=-1\n",
    "            self._maxCut=-1\n",
    "            \n",
    "        elif ( self._minimaspositions is None ):\n",
    "            #sig.argrelmin(Comparator.chi2measure(signal,shaplet),order=int(len(shaplet)/2),mode=\"wrap\")[0]\n",
    "            if(len(self.chi2())<int(len(self.shaplet)/2)):\n",
    "                self._minimaspositions=np.array([np.argmin(self.chi2())])\n",
    "                self._minimas=self._chi2[self._minimaspositions]\n",
    "                self._minCut=min(self._chi2)\n",
    "                self._maxCut=max(self._chi2)\n",
    "            else:\n",
    "                self._minimaspositions=sig.argrelmin(self.chi2(),order=int(len(self.shaplet)/2),mode=\"wrap\")[0]\n",
    "                self._minimas=self._chi2[self._minimaspositions]\n",
    "                self._minCut=min(self._minimas)\n",
    "                self._maxCut=max(self._minimas)\n",
    "    \n",
    "    def minimaspositions(self,cut=None):\n",
    "        self.__findminimas()\n",
    "        return self._minimaspositions if cut is None else self._minimaspositions[self._minimas<=cut]\n",
    "    \n",
    "    def minimas(self,cut=None):\n",
    "        self.__findminimas()\n",
    "        return self._minimas if cut is None else self._minimas[self._minimas<=cut]\n",
    "\n",
    "    def findcut(self,precision=1e-2):\n",
    "        if not (self._efficientCut is None):\n",
    "            return\n",
    "\n",
    "        if(np.array_equal(self._chi2,np.array(-1))):\n",
    "            self._efficientCut=-1\n",
    "            return\n",
    "\n",
    "        if not utilities.noholes(self.__positionsforcut(self._maxCut),len(self.shaplet)):  \n",
    "            self._efficientCut=-1\n",
    "            return\n",
    "        \n",
    "        self.__findminimas() \n",
    "        low=self._minCut\n",
    "        high=self._maxCut\n",
    "   #     print(low)\n",
    "  #      print(high) \n",
    " #       print(precision)\n",
    "        while high - low > precision:\n",
    "  #          print(low,end=\" it got inside \")\n",
    " #           print(high)\n",
    "            mid = (low + high) / 2\n",
    "            if utilities.noholes(self.__positionsforcut(mid),len(self.shaplet)):  \n",
    "                high = mid  # Move left if `foo(mid)` is True\n",
    "            else:\n",
    "                low = mid   # Move right if `foo(mid)` is False\n",
    "                \n",
    "        self._efficientCut=high\n",
    "\n",
    "    def __positionsforcut(self,cut):\n",
    "        return sorted(self._minimaspositions[self._minimas<=cut])\n",
    "\n",
    "    def min(self):\n",
    "        self.__findminimas()\n",
    "        return self._minCut\n",
    "\n",
    "    def efficient(self):\n",
    "        self.__findminimas()\n",
    "        self.findcut()\n",
    "        return self._efficientCut\n",
    "    \n",
    "    def max(self):\n",
    "        self.__findminimas()\n",
    "        return self._maxCut\n",
    "\n",
    "    def coveredarea(self):\n",
    "        area=0\n",
    "        minpositions=self.minimaspositions()\n",
    "        for i in range(len(minpositions)):\n",
    "            if(i==len(minpositions)-1):\n",
    "                if(self.signallength-minpositions[i]>=len(self.shaplet)):\n",
    "                    area+=len(self.shaplet)\n",
    "                else:\n",
    "                    area+=self.signallength-minpositions[i]\n",
    "            else:\n",
    "                el=minpositions[i]\n",
    "                nextel=minpositions[i+1]\n",
    "                if( el+len(self.shaplet) > nextel ):\n",
    "                    area+=(nextel-el)\n",
    "                else:\n",
    "                    area+=len(self.shaplet)\n",
    "       #     print(area)      \n",
    "        return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5b4c18-c052-4b77-8e3a-8dae4b346646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class scaledComparator(Comparator):\n",
    "    def __init__(self,data:Data,column,shaplet:Shaplet):\n",
    "        super().__init__(data,column,shaplet)\n",
    "        self.alpha=super()._Comparator__computealpha()\n",
    "        self._chi2=self.scaledchi2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "120cfaf7-463e-4a74-886e-1e87e368ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalizedComparator(Comparator):\n",
    "    def __init__(self,data:Data,column,shaplet:Shaplet):\n",
    "        # definition of a,b,c and d:\n",
    "        # a*S+b=c*shaplet+d\n",
    "        super().__init__(data,column,shaplet)\n",
    "        self.a=self.data.alpha(self.column) \n",
    "        self.b=self.data.beta(self.column) \n",
    "        self.c=self.shaplet.alpha\n",
    "        self.d=self.shaplet.beta\n",
    "\n",
    "        self._chi2= self.normalizedchi2(self.data.getcolumn(self.column),self.shaplet.series)\n",
    "    \n",
    "    def normalizedchi2(self,signal,shapletseries):\n",
    "        #NEED TO CHECK IF THE SHAPLET SERIES IS LOADED IF NOT THEN I LL HAE AN ERROR \n",
    "        if(len(signal)<len(shapletseries)): #By convention the difference is -1 if the sizes arent matching\n",
    "            return np.array(-1)\n",
    "            \n",
    "        difference=[] #diffrence between shaplet & signal\n",
    "        mean_=np.mean(shapletseries)\n",
    "        shapletlength=len(shapletseries)\n",
    "        for i in range(0,len(signal)-len(shapletseries)):\n",
    "            alpha=self.alpha[i]\n",
    "            #YOU ARE HERE\n",
    "            #MAKE SURE YOU ARE PROGRAMMING THE RIGHT DIFFERENCE FORMULAE !!\n",
    "            diff=np.sum(np.power(self.a*signal[i:i+len(shapletseries)]+self.b-self.c*shapletseries-self.d,2) /\n",
    "                        (( (self.a**2)*np.mean(signal[i:i+len(shapletseries)]) + (self.c **2)*mean_ )*8*len(shapletseries)))\n",
    "            difference.append(diff)\n",
    "        difference=np.array(difference)\n",
    "        return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb912c9b-5784-4130-823b-781e657be727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def superpose(self,comparator:Comparator,xlim=None,title=None,cut=None,cleaned=False,cleanedopacity=0.8,showing=True,\n",
    "                  initiate=True,draw=True,color='r'):\n",
    "        #ADD A TITLE FOR THIS PLOT\n",
    "        if cleaned==True:\n",
    "            opacity=cleanedopacity\n",
    "        else:\n",
    "            opacity=0.5\n",
    "        shaplet=comparator.shaplet\n",
    "        data=comparator.data\n",
    "        if(initiate):\n",
    "            plt.figure()   \n",
    "        signal=data.getcolumn(comparator.column)\n",
    "        if(xlim is not None):\n",
    "            plt.xlim(np.array(xlim)/8)\n",
    "        if(title is not None):\n",
    "            plt.title(title)\n",
    "        else:\n",
    "            plt.title(\"lc number: \"+str(comparator.data.lcnumber))\n",
    "        minimaspositions=comparator.minimaspositions(cut)\n",
    "        \n",
    "        #just to test:\n",
    "        print(minimaspositions)\n",
    "        #\n",
    "     #   minimaspositions=sig.argrelmin(Comparator.chi2measure(signal,shaplet),order=int(len(shaplet)/2),mode=\"wrap\")[0]\n",
    "        if(draw):\n",
    "            plt.plot(np.array(range(len(signal)))/8,signal,color='b')  #EVERYTHING IN SECONDS FROM NOW ON !!!\n",
    "  #                plt.plot(np.array( range(index,index+min(len(shaplet),comparator.signallength)) )/8,\n",
    " #                             shaplet.series[:min(len(shaplet),comparator.signallength)],color='r',alpha=0.5)\n",
    "#\n",
    "\n",
    "\n",
    "        # \n",
    "        min_chi2_index = min(minimaspositions, key=lambda idx: comparator.chi2()[idx])\n",
    "        \n",
    "        if (isinstance(comparator,normalizedComparator)):\n",
    "             for i in range(len(minimaspositions)):\n",
    "                index=minimaspositions[i]\n",
    "                if(i==len(minimaspositions)-1 and len(shaplet)+index >=comparator.signallength):\n",
    "                    plt.plot(np.array(range(index,comparator.signallength))/8,\n",
    "    abs((comparator.c/comparator.a))*shaplet.series[:comparator.signallength-index]+(comparator.d-comparator.b)/comparator.a,\n",
    "                    color=color,alpha=opacity)\n",
    "                else:\n",
    "                    plt.plot(np.array(range(index,index+len(shaplet)))/8,comparator.c*shaplet.series+comparator.d,\n",
    "                             color=color,alpha=opacity)\n",
    "                    \n",
    "        else:\n",
    "            for i in range(len(minimaspositions)):\n",
    "                index=minimaspositions[i]\n",
    "                #\n",
    "                # Opacity and color logic\n",
    "                current_opacity = 1.0 if index == min_chi2_index else opacity\n",
    "                current_color =  color  #'green' if index == min_chi2_index else\n",
    "\n",
    "                if i == len(minimaspositions) - 1 and len(shaplet) + index >= comparator.signallength:\n",
    "                    plt.plot(np.array(range(index, comparator.signallength)) / 8,\n",
    "                             comparator.alpha[index] * shaplet.series[:comparator.signallength - index],\n",
    "                             color=current_color, alpha=current_opacity)\n",
    "                else:\n",
    "                    plt.plot(np.array(range(index, index + len(shaplet))) / 8,\n",
    "                             comparator.alpha[index] * shaplet.series,\n",
    "                             color=current_color, alpha=current_opacity)\n",
    "                    \n",
    "        plt.xlabel(\"time in s\")\n",
    "        plt.ylabel(\"intensity count /s\")\n",
    "        if(showing):\n",
    "            plt.show()\n",
    "\n",
    "    def plotshapletsonlc(lightcurve, orderedshapletlist, indexes, shapletdictionary, color_dict,min_chi2_index=None, opacity=0.3):\n",
    "        # Step 1: Create a unique color for each shaplet number\n",
    "        unique_shaplets = list(set(orderedshapletlist))\n",
    "        n_shaplets = len(unique_shaplets)\n",
    "\n",
    "        # Step 2: Plot the lightcurve\n",
    "        plt.plot(np.arange(len(lightcurve)) / 8, lightcurve, color='blue', alpha=0.7, label='Lightcurve')\n",
    "\n",
    "        # Step 3: Plot each shaplet at the given start index\n",
    "        for i, shaplet_num in enumerate(orderedshapletlist):\n",
    "            start_idx = indexes[i]\n",
    "            shaplet = shapletdictionary[shaplet_num]  # Assuming shapletdictionary[shaplet_num] has attribute 'series' and 'length' or just is a 1D array\n",
    "\n",
    "            # Current color from dictionary\n",
    "            current_color = color_dict[shaplet_num]\n",
    "\n",
    "            # Current opacity (full opacity if this is the min chi2 index, else reduced)\n",
    "            current_opacity = 1.0 if (min_chi2_index is not None and i == min_chi2_index) else opacity\n",
    "\n",
    "            # Determine end index\n",
    "            end_idx = start_idx + len(shaplet)\n",
    "            if end_idx > len(lightcurve):\n",
    "                # Trim shaplet if it runs past the lightcurve length\n",
    "                plot_x = np.arange(start_idx, len(lightcurve)) / 8\n",
    "                plot_y = shaplet[:len(lightcurve) - start_idx]\n",
    "            else:\n",
    "                plot_x = np.arange(start_idx, end_idx) / 8\n",
    "                plot_y = shaplet\n",
    "\n",
    "            # Plot the shaplet on the lightcurve\n",
    "            plt.plot(plot_x, plot_y, color=current_color, alpha=current_opacity)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Signal')\n",
    "        plt.title('Lightcurve with Shaplets Overlay')\n",
    "        plt.show()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    def superposemany(self,comparators,xlim=None,title=None,cut=None,cleaned=None):\n",
    "        plt.figure() #comparator have the same lc\n",
    "        signal=comparators[0].data.getcolumn(comparators[0].column)\n",
    "        plt.plot(np.array(range(len(signal)))/8,signal,color='b')  #EVERYTHING IN SECONDS FROM NOW ON !!!\n",
    "        n = len(comparators)\n",
    "        color_map = plt.cm.get_cmap('tab20', n) \n",
    "        i=0\n",
    "        for i,comparator in enumerate(comparators):  # DONT TO SAVE NOW THIS MESSAGE IS NEW !!------------------------------\n",
    "            color = color_map(i)\n",
    "            self.superpose(comparator,cleaned=False,showing=False,initiate=False,draw=False,color=color) #draw for srawing the signal\n",
    "        plt.show()\n",
    "        \n",
    "    def superposeatminima(self,comparator:Comparator,xlim=None,title=None):\n",
    "        self.superpose(comparator,cut=comparator.min())\n",
    "    \n",
    "    def showchi2(self,comparator:Comparator):\n",
    "        plt.figure()\n",
    "        plt.title(\"lc number: \"+str(comparator.data.lcnumber))\n",
    "        plt.plot(np.array(range(len(comparator.chi2())))/8,comparator.chi2())\n",
    "        plt.xlabel(\"window index\")\n",
    "        plt.ylabel(\"chi^2\")\n",
    "        plt.show()\n",
    "\n",
    "    def shownormalized(self,arr,title=\" \"):\n",
    "        if(isinstance(arr,Shaplet)):\n",
    "            utilities.show(utilities.normalize(arr.series),title=title)\n",
    "        else:\n",
    "            utilities.show(utilities.normalize(arr),title=title)\n",
    "    \n",
    "        \n",
    "    def showscaledchi2(self,comparator:Comparator):\n",
    "        plt.figure()\n",
    "        plt.title(\"lc number: \"+str(comparator.data.lcnumber))\n",
    "        plt.plot(np.array(range(len(comparator.scaledchi2())))/8,comparator.scaledchi2())\n",
    "        plt.xlabel(\"window index\")\n",
    "        plt.ylabel(\"scaled chi^2\")\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def showlow(self,data:Data):\n",
    "        plt.figure()\n",
    "        plt.title(\"lc number: \"+str(data.lcnumber))\n",
    "        plt.plot(data.low())\n",
    "        plt.xlabel(\"time in s\")\n",
    "        plt.ylabel(\"intensity count /s\")\n",
    "        plt.show()\n",
    "\n",
    "    def shownormalizedlow(self,data:Data):\n",
    "        plt.figure()\n",
    "        plt.title(\"lc number: \"+str(data.lcnumber))\n",
    "        plt.plot(data.alpha(\"low\")*data.low()+data.beta(\"low\"))\n",
    "        plt.xlabel(\"time in s\")\n",
    "        plt.ylabel(\"intensity count /s\")\n",
    "        plt.show()\n",
    "    \n",
    "    def show(self,series,title=\" \"):\n",
    "        if(isinstance(series,Shaplet)):\n",
    "            utilities.show(series.series,title=title)\n",
    "        else:\n",
    "            utilities.show(series,title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "185e2f43-6b60-4976-b04b-d475039a566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmaxefficient(list_,comparators:list[Comparator]):\n",
    "    \"returns dataframe of min max and efficient cuts for each comparator in comparators\"\n",
    "    cuts=pd.DataFrame(columns=['index','min', 'efficient', 'max'])\n",
    "  #  print(cuts)\n",
    "    for index in list_:\n",
    " #       print(index)\n",
    "        cuts.loc[len(cuts)]=[index,comparators[index].min(),comparators[index].efficient(),comparators[index].max()]\n",
    "    return cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "205adc63-0a3b-4493-9431-4a7ac0508ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparewith(list_,column,shaplet:Shaplet):\n",
    "    \"returns a list of comparators of Data(i) and shaplet where i reperents elements in list_\"\n",
    "    comparators=[]\n",
    "    for i in list_:\n",
    "        comparators.append(Comparator(Data(i),column,shaplet))\n",
    "    return comparators\n",
    "\n",
    "def comparewithnormalized(list_,column,shaplet:Shaplet):\n",
    "    \"returns a list of comparators of Data(i) and shaplet where i reperents elements in list_\"\n",
    "    comparators=[]\n",
    "    for i in list_:\n",
    "        comparators.append(Comparator(normalizedData(i),column,shaplet))\n",
    "    return comparators\n",
    "\n",
    "\n",
    "def scaledcomparewith(list_,column,shaplet:Shaplet):\n",
    "    \"returns a list of comparators of Data(i) and shaplet where i reperents elements in list_\"\n",
    "    comparators=[]\n",
    "    for i in list_:\n",
    "        comparators.append(scaledComparator(Data(i),column,shaplet))\n",
    "    return comparators\n",
    "\n",
    "def normalizedcomparewith(list_,column,shaplet:Shaplet):\n",
    "    \"returns a list of comparators of Data(i) and shaplet where i reperents elements in list_\"\n",
    "    comparators: List[normalizedComparator] = []\n",
    "    for i in list_:\n",
    "        comparators.append(normalizedComparator(Data(i),column,shaplet))\n",
    "    return comparators\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d7343b-08be-4950-874d-cf0200b4c577",
   "metadata": {},
   "source": [
    "#  With what lcs should i compare to find best matches to then take the mean ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1435206c-7492-4c49-8f5f-bbcf1d695ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanormalized(shaplet,column,samedir=True,cut=2):\n",
    "    #TODO: NEED TO HANDLE SHAPLETS DEFINED WITHOUT ANY LCNUMBER !!!\n",
    "    #cleaning is bad for lambda class,need to handle that !!  Since number of elements isnt that much\n",
    "    \n",
    "  #  print(\"updated\") # to eraze later\n",
    "   # print(\"len shap\",len(shaplet))\n",
    "    print(\"updated 5\")\n",
    "    if(not samedir):\n",
    "        class2key=utilities.loadjson(\"../class2key\")  \n",
    "        key2class=utilities.loadjson(\"../key2class\")\n",
    "    else:\n",
    "        class2key=utilities.loadjson(\"class2key\")  \n",
    "        key2class=utilities.loadjson(\"key2class\")  \n",
    "        \n",
    " #   print(key2class[str(shaplet.lcnumber)])\n",
    "    comparators=normalizedcomparewith(class2key[key2class[str(shaplet.lcnumber)]],column,shaplet) # reference for cleaning ???\n",
    "    print(len(comparators))                                                                                        # I have chosen the shaplet class\n",
    "    D=[]\n",
    "    for comparator in comparators:\n",
    "        try:\n",
    "            for minpos in comparator.minimaspositions():\n",
    "                if(comparator.chi2()[minpos]<cut):\n",
    "                    D.append((comparator.data.lcnumber,minpos))\n",
    "        except:\n",
    "            #TODO: I WILL HANDLE ERRORS LATER,MORE LIKELY DUE TO THE LENGTH COMPARISON THING\n",
    "            continue\n",
    "    Sum=np.zeros(len(shaplet))\n",
    "    print(len(D))\n",
    "    for el in D:\n",
    "        lcnumber=el[0]\n",
    "        minpos=el[1]\n",
    "        \n",
    "  #      utilities.show(utilities.normalize(Data(lcnumber).getcolumn(\"low\")[minpos:minpos+len(shaplet)]))\n",
    "\n",
    "        Sum+=utilities.normalize(Data(lcnumber).getcolumn(\"low\")[minpos:minpos+len(shaplet)]) #NORMALIZE The serie first\n",
    "    res=(Sum + utilities.normalize(shaplet.series))/(1+len(D))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (Shaplet(shaplet.lcnumber,column,shaplet.start,len(shaplet),series=res),D) #change parameters to None,or depending on the clean shaplet get the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc0ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e0af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1693d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb226415-7587-4b4f-a780-5f2f445a9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(shaplet,column,samedir=True,cut=2):\n",
    "    #TODO: NEED TO HANDLE SHAPLETS DEFINED WITHOUT ANY LCNUMBER !!!\n",
    "    #cleaning is bad for lambda class,need to handle that !!  Since number of elements isnt that much\n",
    "    \n",
    "  #  print(\"updated\") # to eraze later\n",
    "   # print(\"len shap\",len(shaplet))\n",
    "    #print(\"updated 5\")\n",
    "    if(not samedir):\n",
    "        class2key=utilities.loadjson(\"../class2key\")  \n",
    "        key2class=utilities.loadjson(\"../key2class\")\n",
    "    else:\n",
    "        class2key=utilities.loadjson(\"class2key\")  \n",
    "        key2class=utilities.loadjson(\"key2class\")  \n",
    "        \n",
    " #   print(key2class[str(shaplet.lcnumber)])\n",
    "    comparators=comparewith(class2key[key2class[str(shaplet.lcnumber)]],column,shaplet) # reference for cleaning ???\n",
    "                                                                                            # I have chosen the shaplet class\n",
    "    D=[]\n",
    "    for comparator in comparators:\n",
    "        try:\n",
    "            for minpos in comparator.minimaspositions():\n",
    "                if(comparator.chi2()[minpos]<cut):\n",
    "                    D.append((comparator.data.lcnumber,minpos))\n",
    "        except:\n",
    "            #TODO: I WILL HANDLE ERRORS LATER,MORE LIKELY DUE TO THE LENGTH COMPARISON THING\n",
    "            continue\n",
    "    Sum=np.zeros(len(shaplet))\n",
    "    for el in D:\n",
    "        lcnumber=el[0]\n",
    "        minpos=el[1]\n",
    "        \n",
    "  #      utilities.show(utilities.normalize(Data(lcnumber).getcolumn(\"low\")[minpos:minpos+len(shaplet)]))\n",
    "\n",
    "        Sum+=utilities.normalize(Data(lcnumber).getcolumn(\"low\")[minpos:minpos+len(shaplet)]) #NORMALIZE The serie first\n",
    "    res=(Sum + utilities.normalize(shaplet.series))/(1+len(D))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (Shaplet(shaplet.lcnumber,column,shaplet.start,len(shaplet),series=res),D) #change parameters to None,or depending on the clean shaplet get the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8003e904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkey2class=utilities.loadjson(\"key2class\")\\nclass2key=utilities.loadjson(\"class2key\")\\nvisualizer=Visualizer()'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "key2class=utilities.loadjson(\"key2class\")\n",
    "class2key=utilities.loadjson(\"class2key\")\n",
    "visualizer=Visualizer()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad89d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c13f2609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in class2key[\"rho\"]:\\n    alpha[i]=utilities.findalpha(Data(i).getcolumn(\"low\"))\\n    normalizeddata[i]=normalizedData(i)\\n    '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in class2key[\"rho\"]:\n",
    "    alpha[i]=utilities.findalpha(Data(i).getcolumn(\"low\"))\n",
    "    normalizeddata[i]=normalizedData(i)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1b2bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha=utilities.findalpha(Data(432).getcolumn(\"low\"))\n",
    "#mean=np.mean(Data(432).getcolumn(\"low\")[0:300])\n",
    "#shaplet0=Shaplet(432,\"low\",0,300,mean=mean,alpha=alpha,isnormalized=True) #column,start,length,isaclean=False,series=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a38b8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comp=normalizedComparator(normalizeddata[181],\"low\",shaplet0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9db98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c55ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f086086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%matplotlib widget\\nvisualizer.superpose(comp)\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%matplotlib widget\n",
    "visualizer.superpose(comp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e18e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5b3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e50a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6abc75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb5de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22511fdb-64e3-406f-b2be-51ec621bfade",
   "metadata": {},
   "source": [
    "# computed covered area of the shaplet on rho (change the function to count for shaplet that dont end fully) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cabafb9-b8b9-4ab9-8422-7c2ef7c15122",
   "metadata": {},
   "source": [
    "# PROGRAM NOW THE DIFFERENT SHAPLETS ESPECIALLY THE SMALL ONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5968d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find if data is continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f2825ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndatatable=pd.read_csv(\"classified_lcs/grs1915_lc\"+str(lcnumber)+\".txt\",sep=\"\\t\",skiprows=[0, 1], header=None)\\ndatatable.columns=[\\'time\\', \\'total\\',\\'low\\',\\'mid\\',\\'high\\'] \\n\\nfirstline=pd.read_csv(\"classified_lcs/grs1915_lc\"+str(self.lcnumber)+\".txt\",sep=\"\\t\",nrows=1, header=None).iloc[0,0]\\nprefix=\"# class : \"\\nself.dataclass=firstline[len(prefix):].strip()\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "datatable=pd.read_csv(\"classified_lcs/grs1915_lc\"+str(lcnumber)+\".txt\",sep=\"\t\",skiprows=[0, 1], header=None)\n",
    "datatable.columns=['time', 'total','low','mid','high'] \n",
    "\n",
    "firstline=pd.read_csv(\"classified_lcs/grs1915_lc\"+str(self.lcnumber)+\".txt\",sep=\"\t\",nrows=1, header=None).iloc[0,0]\n",
    "prefix=\"# class : \"\n",
    "self.dataclass=firstline[len(prefix):].strip()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb4c6b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport os\\n\\nfolder = \"classified_lcs\"\\nnum_files = len(class2key[\"rho\"])  # Change this to your actual number of light curves\\n\\nlast_times = []\\ntime_issues = []\\n\\nfor lcnumber in range(num_files):\\n    filepath = os.path.join(folder, \"grs1915_lc\"+str(class2key[\"rho\"][lcnumber])+\".txt\")\\n    \\n    if not os.path.isfile(filepath):\\n        print(f\"❌ File not found: {filepath}\")\\n        continue\\n\\n    datatable = pd.read_csv(filepath, sep=\"\\t\", skiprows=[0, 1], header=None)\\n    datatable.columns = [\\'time\\', \\'total\\', \\'low\\', \\'mid\\', \\'high\\']\\n    \\n    time_col = datatable[\\'time\\']\\n    \\n    # Check if time is increasing\\n    if not time_col.is_monotonic_increasing:\\n        time_issues.append((filepath, \"Time column not strictly increasing\"))\\n    \\n    # Check if time step is constant\\n    time_diffs = time_col.diff().dropna()\\n    if time_diffs.nunique() > 1:\\n        time_issues.append((filepath, \"Time step not constant\"))\\n    \\n    first_time = time_col.iloc[0]\\n    last_time = time_col.iloc[-1]\\n    last_times.append((filepath, first_time, last_time))\\n\\n# Check if last_time < next_first_time\\ncross_file_issues = []\\nfor i in range(len(last_times) - 1):\\n    current_last = last_times[i][2]\\n    next_first = last_times[i + 1][1]\\n    if current_last >= next_first:\\n        cross_file_issues.append((\\n            last_times[i][0],\\n            last_times[i + 1][0],\\n            f\"last_time={current_last} >= next_first_time={next_first}\"\\n        ))\\n\\n# Summary\\nif not time_issues and not cross_file_issues:\\n    print(\"✅ All time columns are continuous and sequential across files.\")\\nelse:\\n    if time_issues:\\n        print(\"\\n⚠️ Time continuity issues:\")\\n        for issue in time_issues:\\n            print(issue)\\n    if cross_file_issues:\\n        print(\"\\n⚠️ Cross-file time ordering issues:\")\\n        for issue in cross_file_issues:\\n            print(issue)\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder = \"classified_lcs\"\n",
    "num_files = len(class2key[\"rho\"])  # Change this to your actual number of light curves\n",
    "\n",
    "last_times = []\n",
    "time_issues = []\n",
    "\n",
    "for lcnumber in range(num_files):\n",
    "    filepath = os.path.join(folder, \"grs1915_lc\"+str(class2key[\"rho\"][lcnumber])+\".txt\")\n",
    "    \n",
    "    if not os.path.isfile(filepath):\n",
    "        print(f\"❌ File not found: {filepath}\")\n",
    "        continue\n",
    "\n",
    "    datatable = pd.read_csv(filepath, sep=\"\\t\", skiprows=[0, 1], header=None)\n",
    "    datatable.columns = ['time', 'total', 'low', 'mid', 'high']\n",
    "    \n",
    "    time_col = datatable['time']\n",
    "    \n",
    "    # Check if time is increasing\n",
    "    if not time_col.is_monotonic_increasing:\n",
    "        time_issues.append((filepath, \"Time column not strictly increasing\"))\n",
    "    \n",
    "    # Check if time step is constant\n",
    "    time_diffs = time_col.diff().dropna()\n",
    "    if time_diffs.nunique() > 1:\n",
    "        time_issues.append((filepath, \"Time step not constant\"))\n",
    "    \n",
    "    first_time = time_col.iloc[0]\n",
    "    last_time = time_col.iloc[-1]\n",
    "    last_times.append((filepath, first_time, last_time))\n",
    "\n",
    "# Check if last_time < next_first_time\n",
    "cross_file_issues = []\n",
    "for i in range(len(last_times) - 1):\n",
    "    current_last = last_times[i][2]\n",
    "    next_first = last_times[i + 1][1]\n",
    "    if current_last >= next_first:\n",
    "        cross_file_issues.append((\n",
    "            last_times[i][0],\n",
    "            last_times[i + 1][0],\n",
    "            f\"last_time={current_last} >= next_first_time={next_first}\"\n",
    "        ))\n",
    "\n",
    "# Summary\n",
    "if not time_issues and not cross_file_issues:\n",
    "    print(\"✅ All time columns are continuous and sequential across files.\")\n",
    "else:\n",
    "    if time_issues:\n",
    "        print(\"\\n⚠️ Time continuity issues:\")\n",
    "        for issue in time_issues:\n",
    "            print(issue)\n",
    "    if cross_file_issues:\n",
    "        print(\"\\n⚠️ Cross-file time ordering issues:\")\n",
    "        for issue in cross_file_issues:\n",
    "            print(issue)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5530a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790720e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef7955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
